{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46bdfce-8558-4db7-bf6c-e30409103a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#隐藏警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")               #忽略警告信息\n",
    "plt.rcParams['font.sans-serif']    = ['SimHei'] # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False      # 用来正常显示负号\n",
    "plt.rcParams['figure.dpi']         = 100        #分辨率\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3202bf-034c-4a4e-8a39-89925e0007c5",
   "metadata": {},
   "source": [
    "### 读取（下载）MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc5c44b-a5f0-422d-bde6-d4d1c984f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 数据集的均值和标准差为 0.1307 和 0.3081\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='../datasets/mnist', train=True, download=True, transform=transform)  # download=True:如果没有, 下载数据集\n",
    "test_dataset = datasets.MNIST(root='../datasets/mnist', train=False, download=True, transform=transform)  # train=True训练集，=False测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12857fef-94c9-476a-b5e8-38b5a2b4105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b077b1f0-4933-4603-9de1-1ca9bdd53678",
   "metadata": {},
   "source": [
    "### 构建模型\n",
    "**Generator 和 Discriminator**\n",
    "\n",
    "[反卷积(Transposed conv deconv)实现原理（通俗易懂）](https://blog.csdn.net/weixin_39326879/article/details/120797857) : 在GAN中，生成器使用反卷积层将低维随机噪声转换为高分辨率图像"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb638e1-16ba-49d2-9df3-d988baad2961",
   "metadata": {},
   "source": [
    "#### 反卷积层（Deconvolution Layer）\n",
    "\n",
    "反卷积层，也称为**转置卷积层（Transposed Convolution Layer）**，是一种用于上采样的操作。它的作用是将低分辨率的特征图（feature map）转换为高分辨率的特征图。反卷积层在生成对抗网络（GAN）、图像分割、超分辨率等任务中非常常见。\n",
    "\n",
    "\n",
    "| 特性                | 卷积层（Convolution）                          | 反卷积层（Transposed Convolution）            |\n",
    "|---------------------|-----------------------------------------------|-----------------------------------------------|\n",
    "| **目的**            | 下采样，提取特征                              | 上采样，生成高分辨率特征图                    |\n",
    "| **输入与输出关系**  | 输入尺寸 > 输出尺寸                           | 输入尺寸 < 输出尺寸                           |\n",
    "| **计算方式**        | 通过滑动窗口和卷积核计算输出                  | 通过填充和卷积核的转置计算输出                |\n",
    "| **应用场景**        | 特征提取、分类、检测等                        | 图像生成、分割、超分辨率等                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d2b1d-7911-4d8c-bdad-c95b35e44396",
   "metadata": {},
   "source": [
    "#### Generator \n",
    "生成器的目标是从随机噪声（latent vector）和条件（condition）生成逼真的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6ff0a6-5c40-40a0-9f45-4416398709c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim=100, output_dim=1, class_num=10):\n",
    "        '''\n",
    "        初始化生成网络\n",
    "        :param input_dim:输入随机噪声的维度，（随机噪声是为了增加输出多样性）\n",
    "        :param output_dim:生成图像的通道数（灰度图为1，RGB图为3）\n",
    "        :param class_num:图像种类\n",
    "        '''\n",
    "        super(Generator, self).__init__()\n",
    "        \"\"\"\n",
    "         为什么需要拼接随机噪声和条件向量？\n",
    "         拼接随机噪声和条件向量的目的是将两种信息结合起来，作为生成器的输入：\n",
    "         随机噪声：提供生成数据的随机性。\n",
    "         条件向量：提供生成数据的条件信息。\n",
    "         通过拼接，生成器可以根据条件向量生成符合特定条件的数据, 同时确保每次生成的数据会有所不同\n",
    "         \"\"\"\n",
    "        self.input_dim = input_dim + class_num # 生成器的输入维度是随机噪声的维度加上条件向量的维度\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # 全连接层，将输入向量映射到高维空间，然后通过反卷积层生成图像\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128 * 7 * 7),\n",
    "            nn.BatchNorm1d(128 * 7 * 7),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # 反卷积层（转置卷积层），用于将高维特征图逐步上采样为最终图像\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1), # 输入通道数：128, 输出通道数：64, 卷积核大小：4x4, 步幅：2, 填充：1\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n",
    "            nn.Tanh(), # 激活函数，将输出值限制在 [-1, 1] 范围内，适合生成图像\n",
    "        )\n",
    " \n",
    "    def forward(self, input):\n",
    "        x = self.fc(input)\n",
    "        x = x.view(-1, 128, 7, 7) # 将全连接层的输出重塑为特征图的形式\n",
    "        x = self.deconv(x) # 通过反卷积层生成图像\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc6051-e84f-43d4-bf3e-69191210ac66",
   "metadata": {},
   "source": [
    "**Spectral Normalization GAN（SNGAN）的原理**\n",
    "\n",
    "Spectral Normalization（谱归一化）是一种用于稳定 GAN 训练的技术，主要应用于判别器（Discriminator）。能够避免梯度爆炸或梯度消失问题。\n",
    "** 为什么 SNGAN 效果好？**\n",
    "- **稳定训练**：谱归一化有效避免了判别器过于强大导致的梯度消失或梯度爆炸问题。\n",
    "- **无需额外超参数**：谱归一化不需要像 WGAN-GP 那样引入梯度惩罚，简化了训练过程。\n",
    "- **通用性强**：谱归一化可以应用于各种 GAN 架构中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a2f68-9e49-45bd-9419-c483c1bac15e",
   "metadata": {},
   "source": [
    "#### Discriminator \n",
    "判别器的目标是区分输入图像是真实的还是生成的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a66459d5-8040-44d1-9258-edf98b3a29ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.spectral_norm as spectral_norm\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim=1, output_dim=1):\n",
    "        '''\n",
    "        初始化判别网络\n",
    "        :param input_dim:输入通道数\n",
    "        :param output_dim:输出通道数\n",
    "        '''\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # 卷积层，用于提取图像特征（应用谱归一化）\n",
    "        self.conv = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(self.input_dim, 64, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            spectral_norm(nn.Conv2d(64, 128, 4, 2, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        \n",
    "        # 全连接层，将特征图映射为最终的判别结果（应用谱归一化）\n",
    "        self.fc = nn.Sequential(\n",
    "            spectral_norm(nn.Linear(128 * 7 * 7, 1024)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            spectral_norm(nn.Linear(1024, self.output_dim)),\n",
    "        )\n",
    " \n",
    "    def forward(self, input):\n",
    "        x = self.conv(input)\n",
    "        x = x.view(-1, 128 * 7 * 7)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d706986-ed44-4280-a32a-653e04bdfb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNGAN 通常使用 Hinge Loss 作为损失函数\n",
    "def hinge_loss_discriminator(real_scores, fake_scores):\n",
    "    # 判别器损失\n",
    "    real_loss = torch.mean(torch.relu(1 - real_scores))  # 真实图像的损失\n",
    "    fake_loss = torch.mean(torch.relu(1 + fake_scores))  # 生成图像的损失\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "def hinge_loss_generator(fake_scores):\n",
    "    # 生成器损失\n",
    "    return -torch.mean(fake_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dcd94d-780b-491a-b254-1bb6e2b3b64a",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "338ab99f-9789-483d-ab7e-4b7926c4fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, generator, discriminator, optimizer_G, optimizer_D):\n",
    "    generator.train()  # 设置生成器为训练模式\n",
    "    discriminator.train()  # 设置判别器为训练模式\n",
    "\n",
    "    running_loss_G = 0.0\n",
    "    running_loss_D = 0.0\n",
    "\n",
    "    # 使用 tqdm 包裹数据加载器，显示进度条\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    for index, (images, labels) in enumerate(progress_bar):\n",
    "        # 将数据移动到设备\n",
    "        images = images.to(device)\n",
    "        labels = F.one_hot(labels, num_classes=10).float() # 将 labels 转换为 one-hot 编码(对应十个类别)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        # 生成随机噪声\n",
    "        z = torch.randn(batch_size, generator.input_dim - labels.size(1)).to(device)\n",
    "        z = torch.cat([z, labels], dim=1)  # 拼接噪声和条件向量\n",
    "\n",
    "        # 每 50 个 batch 更新一次判别器\n",
    "        if index % 100 == 0:\n",
    "            ### 更新判别器 ###\n",
    "            optimizer_D.zero_grad()\n",
    "            # 真实图像输入判别器\n",
    "            D_real = discriminator(images)\n",
    "            # 生成虚假图像并输入判别器\n",
    "            images_fake = generator(z)\n",
    "            D_fake = discriminator(images_fake.detach())\n",
    "            # 计算判别器损失\n",
    "            D_loss = hinge_loss_discriminator(D_real, D_fake)\n",
    "            D_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            # 统计判别器损失\n",
    "            running_loss_D += D_loss.item()\n",
    "\n",
    "        ### 更新生成器 ###\n",
    "        optimizer_G.zero_grad()\n",
    "        # 生成虚假图像并输入判别器\n",
    "        images_fake = generator(z)\n",
    "        D_fake = discriminator(images_fake)\n",
    "        # 生成器的目标是让判别器认为虚假图像是真实的\n",
    "        G_loss = hinge_loss_generator(D_fake)\n",
    "        # 更新生成器\n",
    "        G_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # 统计生成器损失\n",
    "        running_loss_G += G_loss.item()\n",
    "\n",
    "        # 更新进度条描述\n",
    "        progress_bar.set_postfix(epoch=epoch+1, loss_G=G_loss.item())\n",
    "\n",
    "    avg_loss_G = running_loss_G / len(dataloader)\n",
    "    avg_loss_D = running_loss_D / len(dataloader)\n",
    "    return avg_loss_G, avg_loss_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9a1c0ac-5c59-4f2f-96a2-41bbff0f7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, generator, discriminator):\n",
    "    generator.eval()  # 设置生成器为评估模式\n",
    "    discriminator.eval()  # 设置判别器为评估模式\n",
    "\n",
    "    running_loss_G = 0.0\n",
    "    running_loss_D = 0.0\n",
    "\n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        progress_bar = tqdm(dataloader, desc=\"Evaluating\", leave=False)\n",
    "        for images, labels in progress_bar:\n",
    "            # 将数据移动到设备\n",
    "            images = images.to(device)\n",
    "            labels = F.one_hot(labels, num_classes=10).float()\n",
    "            labels = labels.to(device)\n",
    "            batch_size = images.size(0)\n",
    "\n",
    "            # 生成随机噪声\n",
    "            z = torch.randn(batch_size, generator.input_dim - labels.size(1)).to(device)\n",
    "            z = torch.cat([z, labels], dim=1)  # 拼接噪声和条件向量\n",
    "\n",
    "            # 真实标签和虚假标签\n",
    "            y_real = torch.ones(batch_size, 1).to(device)\n",
    "            y_fake = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "            ### 计算判别器损失 ###\n",
    "            # 真实图像输入判别器\n",
    "            D_real = discriminator(images)\n",
    "            # 生成虚假图像并输入判别器\n",
    "            images_fake = generator(z)\n",
    "            D_fake = discriminator(images_fake)\n",
    "            D_loss = hinge_loss_discriminator(D_real, D_fake)\n",
    "\n",
    "            ### 计算生成器损失 ###\n",
    "            G_loss = hinge_loss_generator(D_fake)\n",
    "\n",
    "            # 统计损失\n",
    "            running_loss_G += G_loss.item()\n",
    "            running_loss_D += D_loss.item()\n",
    "\n",
    "            # 更新进度条描述\n",
    "            progress_bar.set_postfix(epoch=epoch+1, loss_G=G_loss.item(), loss_D=D_loss.item())\n",
    "\n",
    "    avg_loss_G = running_loss_G / len(dataloader)\n",
    "    avg_loss_D = running_loss_D / len(dataloader)\n",
    "    return avg_loss_G, avg_loss_D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5dd65b-9f0f-4b68-bc34-57509ba09d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成器和判别器\n",
    "generator = Generator(input_dim=100, output_dim=1, class_num=10).to(device)\n",
    "discriminator = Discriminator(input_dim=1, output_dim=1).to(device)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# loss_fn = nn.BCELoss() # GAN 的损失函数通常使用二元交叉熵损失（Binary Cross Entropy Loss）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f76f6d-afc1-460d-8257-e76301003aad",
   "metadata": {},
   "source": [
    "#### 为什么在 GAN 中使用 `betas=(0.5, 0.999)`？\n",
    "\n",
    "在 GAN 的训练中，生成器和判别器是两个对抗的模型，训练过程非常不稳定。为了加快收敛并提高稳定性，通常会对优化器的超参数进行调整：\n",
    "\n",
    "1. **`beta1=0.5`**：\n",
    "   - 使优化器更关注当前梯度，减少历史梯度的影响。\n",
    "   - 这有助于生成器和判别器更快地响应对方的更新，从而加快对抗训练的进程。\n",
    "\n",
    "2. **`beta2=0.999`**：\n",
    "   - 保持对梯度方差的平滑估计，避免优化器过于敏感。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b4ba4-bcbf-49c0-9c52-25b8ca7d4613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train_loss_G:-0.338, Train_loss_D:0.019, Test_loss_G:0.006, Test_loss_D:1.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train_loss_G:0.666, Train_loss_D:0.010, Test_loss_G:0.568, Test_loss_D:0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train_loss_G:1.140, Train_loss_D:0.005, Test_loss_G:0.507, Test_loss_D:0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train_loss_G:1.230, Train_loss_D:0.004, Test_loss_G:1.537, Test_loss_D:0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train_loss_G:1.223, Train_loss_D:0.002, Test_loss_G:1.060, Test_loss_D:0.087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train_loss_G:1.417, Train_loss_D:0.002, Test_loss_G:1.263, Test_loss_D:0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train_loss_G:1.348, Train_loss_D:0.002, Test_loss_G:1.113, Test_loss_D:0.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train_loss_G:1.364, Train_loss_D:0.002, Test_loss_G:0.734, Test_loss_D:0.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train_loss_G:1.511, Train_loss_D:0.002, Test_loss_G:0.863, Test_loss_D:0.170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10, Train_loss_G:1.590, Train_loss_D:0.002, Test_loss_G:1.373, Test_loss_D:0.048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:11, Train_loss_G:1.448, Train_loss_D:0.001, Test_loss_G:1.559, Test_loss_D:0.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12, Train_loss_G:1.449, Train_loss_D:0.001, Test_loss_G:1.904, Test_loss_D:0.159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13, Train_loss_G:1.454, Train_loss_D:0.001, Test_loss_G:1.265, Test_loss_D:0.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14, Train_loss_G:1.337, Train_loss_D:0.001, Test_loss_G:0.901, Test_loss_D:0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15, Train_loss_G:1.556, Train_loss_D:0.001, Test_loss_G:1.968, Test_loss_D:0.157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16, Train_loss_G:1.468, Train_loss_D:0.001, Test_loss_G:1.727, Test_loss_D:0.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17, Train_loss_G:1.466, Train_loss_D:0.001, Test_loss_G:1.406, Test_loss_D:0.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:18, Train_loss_G:1.452, Train_loss_D:0.000, Test_loss_G:1.121, Test_loss_D:0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  76%|███████████████████████████████████▏          | 1433/1875 [00:25<00:07, 56.67it/s, epoch=19, loss_G=1.2]"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "num_epochs = 30\n",
    "train_loss_G = []\n",
    "train_loss_D = []\n",
    "test_loss_G = []\n",
    "test_loss_D = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # 训练\n",
    "    epoch_train_loss_G, epoch_train_loss_D = train(train_loader, generator, discriminator, optimizer_G, optimizer_D)\n",
    "\n",
    "    # 在测试集上评估\n",
    "    epoch_test_loss_G, epoch_test_loss_D = evaluate(test_loader, generator, discriminator)\n",
    "\n",
    "    # 记录损失\n",
    "    train_loss_G.append(epoch_train_loss_G)\n",
    "    train_loss_D.append(epoch_train_loss_D)\n",
    "    test_loss_G.append(epoch_test_loss_G)\n",
    "    test_loss_D.append(epoch_test_loss_D)\n",
    "\n",
    "    # 打印训练和测试结果\n",
    "    template = ('Epoch:{:2d}, Train_loss_G:{:.3f}, Train_loss_D:{:.3f}, Test_loss_G:{:.3f}, Test_loss_D:{:.3f}')\n",
    "    print(template.format(epoch+1, epoch_train_loss_G, epoch_train_loss_D, epoch_test_loss_G, epoch_test_loss_D))\n",
    "\n",
    "print(\"训练完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0464f73e-cdf8-41ae-a3ff-5ca64fc8a295",
   "metadata": {},
   "source": [
    "### 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa7bec7-b7fe-4b38-bcab-d4cebf4800d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(num_epochs)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_loss_G, label='Training Generator Loss')\n",
    "plt.plot(epochs_range, train_loss_D, label='Training Discriminator Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, test_loss_G, label='Test Generator Loss')\n",
    "plt.plot(epochs_range, test_loss_D, label='Test Discriminator Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e77fd-589a-4752-afde-a386b264e73a",
   "metadata": {},
   "source": [
    "### 效果展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d399db-c56a-446c-b8e9-19baadbcf4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_digit_image(generator, digit, noise_dim=100):\n",
    "    # 检查输入的数字是否合法\n",
    "    if digit < 0 or digit > 9:\n",
    "        raise ValueError(\"输入的数字必须在 0 到 9 之间\")\n",
    "\n",
    "    # 生成随机噪声\n",
    "    z = torch.randn(1, noise_dim)  # 生成一个随机噪声\n",
    "\n",
    "    # 生成条件向量（one-hot 编码）\n",
    "    class_num = 10  # 类别数\n",
    "    label = torch.tensor([digit])  # 将数字转换为张量\n",
    "    label_one_hot = torch.nn.functional.one_hot(label, num_classes=class_num).float()  # 转换为 one-hot 编码\n",
    "\n",
    "    # 拼接随机噪声和条件向量\n",
    "    generator_input = torch.cat([z, label_one_hot], dim=1).to(device)\n",
    "\n",
    "    # 生成图像\n",
    "    generator.eval()  # 设置生成器为评估模式\n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        generated_image = generator(generator_input)\n",
    "\n",
    "    # 将生成的图像从张量转换为 numpy 数组\n",
    "    generated_image = generated_image.cpu().numpy()\n",
    "\n",
    "    # 将图像从 [-1, 1] 范围转换到 [0, 1] 范围\n",
    "    generated_image = (generated_image + 1) / 2\n",
    "\n",
    "    # 去掉通道维度（灰度图）\n",
    "    generated_image = generated_image.squeeze()\n",
    "\n",
    "    return generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e13bdb3-1256-4f9f-a1a5-fd6265d9a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个 4x3 的子图网格\n",
    "fig, axes = plt.subplots(4, 3, figsize=(8, 10))\n",
    "fig.suptitle('Generated Digits (0-9)', fontsize=16)\n",
    "\n",
    "# 生成并显示每个数字的图像\n",
    "for digit in range(10):\n",
    "    generated_image = generate_digit_image(generator, digit)\n",
    "    # 计算子图的位置\n",
    "    row = digit // 3  # 行索引\n",
    "    col = digit % 3   # 列索引\n",
    "\n",
    "    # 显示图像\n",
    "    ax = axes[row, col]\n",
    "    ax.imshow(generated_image, cmap='gray')\n",
    "    ax.set_title(f'Digit: {digit}')\n",
    "    ax.axis('off')  # 关闭坐标轴\n",
    "\n",
    "    # 隐藏多余的子图（因为 10 个数字无法完全填满 4x3 的网格）\n",
    "    for i in range(10, 12):\n",
    "        row = i // 3\n",
    "        col = i % 3\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "# 调整布局并显示\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e427a-8bfb-4dde-a110-d5b4e5cede12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
